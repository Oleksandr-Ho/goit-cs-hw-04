# Огляд проекту та аналіз результатів

## Опис проекту

Цей проект має на меті порівняння трьох методів обробки текстових файлів для пошуку підрядка "Data Science GoIT": послідовної обробки, багатопоточної та багатопроцесорної обробки. 
Для тестування використовуються файли, створені за допомогою бібліотеки Faker, що дозволяє генерувати великі обсяги синтетичних даних для імітації реальних сценаріїв обробки даних.

## Генерація тестових файлів

Файли генеруються з наступними параметрами:
- **Кількість файлів**: 5
- **Записів у файл**: варіюється від 10 до 1,000,000
- **Особливі строки**: Останні рядки першого та останнього файлів містять "Data Science GoIT".

## Результати виконання

Результати виконання для різної кількості записів у файлах представлені у таблиці:

| Кількість записів | Послідовна обробка (сек) | Багатопоточність (сек) | Багатопроцесорність (сек) |
|-------------------|--------------------------|------------------------|---------------------------|
| 10                | 0.00697                  | 0.00101                | 0.09813                   |
| 100,000           | 0.0503                   | 0.0507                 | 0.1283                    |
| 1,000,000         | 0.55184                  | 0.51589                | 0.43848                   |

## Аналіз результатів

### Послідовна та багатопоточна обробка:
- При малому числі записів (10 записів), багатопоточна обробка показала найкращий результат, що відображає мінімізацію часу обробки завдяки ефективному використанню часу вводу/виводу між потоками, незважаючи на обмеження через GIL.

### Багатопроцесорна обробка:
- Цей метод показав значне покращення при збільшенні обсягу даних до 1,000,000 записів, що свідчить про його ефективність при великих обсягах даних, де переваги паралельної обробки на різних ядрах перевищують накладні витрати на створення та управління процесами.

## Висновки

- **Багатопоточність** ефективна при малому обсязі даних, де час обробки є критичним, і потрібно швидко виконувати прості I/O операції.
- **Багатопроцесорність** стає вигіднішою при збільшенні обсягу даних, підтверджуючи, що вона може бути ще ефективнішою при подальшому збільшенні кількості записів у файлах (CPU-bound).
- **Послідовна обробка** забезпечує стабільну продуктивність і може бути привабливою з точки зору простоти використання, особливо коли різниця у часі обробки не є значною для задач з малим обсягом даних. 

Цей аналіз допомагає зрозуміти, у яких умовах кожен із методів обробки файлів є найбільш вигідним, і може слугувати основою для вибору оптимального підходу в залежності від конкретних потреб проекту.